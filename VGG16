import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/0 (e.g. pd.read_csv)
from keras.preprocessing. image import ImageDataGenerator, load_img
# from tensorflow.keras.applications.inception_v3 import InceptionV3
from keras.applications.vgg16 import VGG16
from keras.models import Model
# from tensorflow.keras.applications.inception_v3 import preprocess_input
import tensorflow as tf
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt
from keras import backend
from keras.utils.vis_utils import plot_model
from keras. layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout
from keras.models import Sequential
import matplotlib.pyplot as plt
from glob import glob
import os
from tensorflow.compat.v1 import ConfigProto
from tensorflow. compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.5
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
train_path = './New Plant Diseases Dataset(Augmented)/train'
test_path = './New Plant Diseases Dataset(Augmented)/valid'
# re-size all the images to this
IMAGE_SIZE = [224, 224]
BATCH_SIZE = 32
EPOCHS = 10
RANDOM_SEED = 42

if backend.image_data_format() == 'channels_first':
INPUT_SHAPE = (3, IMAGE_SIZE[0], IMAGE_SIZE[1])
else:
INPUT_SHAPE = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)

print(f'input_shape: {INPUT_SHAPE}')
# Here we will be using imagenet weights

# useful for getting number of output classes
count_of_classes = len(glob(train_path+'/*'))
print(count_of_classes)
# Prepare train/test using ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1./255,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1./255)
#### read directly from directories
training_set = train_datagen.flow_from_directory(train_path,
target_size = tuple(IMAGE_SIZE),
batch_size = BATCH_SIZE,
class_mode = 'categorical')

test_set = test_datagen.flow_from_directory(test_path,
target_size = tuple(IMAGE_SIZE),
batch_size = BATCH_SIZE,
class_mode = 'categorical')

vgg16 = VGG16(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)
# our layers - you can add more if you want
X= Flatten()(vgg16.output)

prediction = Dense(count_of_classes, activation='softmax')(x)

# create a model object
model = Model(inputs=vgg16.input, outputs=prediction)
)

model.compile(loss='categorical_crossentropy',
metrics=['accuracy'],|
optimizer='adam')
plot_model(model, show_shapes=True)
model. summary()
history = model.fit_generator(
training_set,
validation_data=test_set,
epochs=EPOCHS,
steps_per_epoch=len(training_set),
validation_steps=len(test_set)

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='test loss')
plt.legend()
plt.show()
plt.savefig('Loss over Epochs')

# plot the accuracy
plt.plot(history.history['accuracy'], label='train accuracy')
plt.plot(history.history['val_accuracy'], label='test accuracy')
plt.legend()
plt.show()
model.save('model_vgg16.h5')